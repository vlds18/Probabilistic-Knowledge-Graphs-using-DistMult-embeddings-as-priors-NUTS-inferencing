{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel torch-geometric pykeen neo4j pyro-ppl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MpmDPrVhdu3",
        "outputId": "c0ba03a3-aa4a-4d98-bc35-1e70c1a04dbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: pykeen in /usr/local/lib/python3.12/dist-packages (1.11.1)\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.12/dist-packages (1.9.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.6.7)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from pykeen) (1.16.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from pykeen) (8.3.0)\n",
            "Requirement already satisfied: click_default_group in /usr/local/lib/python3.12/dist-packages (from pykeen) (1.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from pykeen) (1.6.1)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from pykeen) (2.8.0+cu126)\n",
            "Requirement already satisfied: optuna>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pykeen) (4.6.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pykeen) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.9.0)\n",
            "Requirement already satisfied: more_click in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.1.3)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.12/dist-packages (from pykeen) (10.8.0)\n",
            "Requirement already satisfied: pystow>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.7.11)\n",
            "Requirement already satisfied: docdata>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.0.5)\n",
            "Requirement already satisfied: class_resolver>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pykeen) (6.0.3)\n",
            "Requirement already satisfied: torch_max_mem>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.1.4)\n",
            "Requirement already satisfied: torch-ppr>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pykeen) (0.0.8)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pykeen) (4.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j) (2025.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl) (3.4.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=2.0.0->pykeen) (1.17.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=2.0.0->pykeen) (6.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=2.0.0->pykeen) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=2.0.0->pykeen) (2.0.44)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=2.0.0->pykeen) (1.3.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->pykeen) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->pykeen) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->pykeen) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=2.0.0->pykeen) (3.2.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->pykeen) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->pykeen) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.11)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->pykeen) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->pykeen) (0.9.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pykeen) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pykeen) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "SwT5idnl9FAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pykeen.datasets import PrimeKG\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn.kge import DistMult\n",
        "from neo4j import GraphDatabase\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.infer import MCMC, NUTS\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "yN-MTWA88vja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c2b95d-7460-48da-f6e0-715c2f6e44f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pykeen.utils:Using opt_einsum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and inspecting the PrimeKG dataset**"
      ],
      "metadata": {
        "id": "mOkz0Vgu-HGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDvoit6whWz2",
        "outputId": "4f761054-4a90-45f3-accc-5fb9c36d2cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pykeen.datasets.base:reordering columns: ['x_name', 'relation', 'y_name']\n",
            "INFO:pykeen.triples.splitting:done splitting triples to groups of sizes [6350753, 809999, 810000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrimeKG(num_entities=129262, num_relations=30, create_inverse_triples=False)\n",
            "Training triples: 6479992\n",
            "Validation triples: 810000\n",
            "Test triples: 809999\n",
            "\n",
            "Sample training triples:\n",
            "'de novo' AMP biosynthetic process -- bioprocess_bioprocess --> AMP biosynthetic process\n",
            "'de novo' AMP biosynthetic process -- bioprocess_protein --> ADSL\n",
            "'de novo' CTP biosynthetic process -- bioprocess_bioprocess --> CTP biosynthetic process\n",
            "'de novo' GDP-L-fucose biosynthetic process -- bioprocess_bioprocess --> GDP-L-fucose biosynthetic process\n",
            "'de novo' IMP biosynthetic process -- bioprocess_bioprocess --> IMP biosynthetic process\n"
          ]
        }
      ],
      "source": [
        "dataset = PrimeKG()\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "train_factory = dataset.training\n",
        "valid_factory = dataset.validation\n",
        "test_factory = dataset.testing\n",
        "\n",
        "print(\"Training triples:\", train_factory.num_triples)\n",
        "print(\"Validation triples:\", valid_factory.num_triples)\n",
        "print(\"Test triples:\", test_factory.num_triples)\n",
        "\n",
        "print(\"\\nSample training triples:\")\n",
        "for triple in train_factory.mapped_triples[:5]:\n",
        "    h, r, t = triple.tolist()\n",
        "    print(\n",
        "        train_factory.entity_id_to_label[h],\n",
        "        \"--\",\n",
        "        train_factory.relation_id_to_label[r],\n",
        "        \"-->\",\n",
        "        train_factory.entity_id_to_label[t],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a readable DataFrame of Knowledge Graph Triples**"
      ],
      "metadata": {
        "id": "wePLnsQAAB5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_lSRQFVhWz2",
        "outputId": "23e1891e-80e7-4b23-df61-35740fe33c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                head               relation  \\\n",
            "0                 'de novo' AMP biosynthetic process  bioprocess_bioprocess   \n",
            "1                 'de novo' AMP biosynthetic process     bioprocess_protein   \n",
            "2                 'de novo' CTP biosynthetic process  bioprocess_bioprocess   \n",
            "3        'de novo' GDP-L-fucose biosynthetic process  bioprocess_bioprocess   \n",
            "4                 'de novo' IMP biosynthetic process  bioprocess_bioprocess   \n",
            "5        'de novo' L-methionine biosynthetic process  bioprocess_bioprocess   \n",
            "6                 'de novo' NAD biosynthetic process  bioprocess_bioprocess   \n",
            "7  'de novo' NAD biosynthetic process from aspartate  bioprocess_bioprocess   \n",
            "8  'de novo' NAD biosynthetic process from trypto...  bioprocess_bioprocess   \n",
            "9                 'de novo' UMP biosynthetic process  bioprocess_bioprocess   \n",
            "\n",
            "                                                tail  \n",
            "0                           AMP biosynthetic process  \n",
            "1                                               ADSL  \n",
            "2                           CTP biosynthetic process  \n",
            "3                  GDP-L-fucose biosynthetic process  \n",
            "4                           IMP biosynthetic process  \n",
            "5                  L-methionine biosynthetic process  \n",
            "6  'de novo' NAD biosynthetic process from aspartate  \n",
            "7                 'de novo' NAD biosynthetic process  \n",
            "8                 'de novo' NAD biosynthetic process  \n",
            "9                           UMP biosynthetic process  \n"
          ]
        }
      ],
      "source": [
        "triples = train_factory.mapped_triples.tolist()\n",
        "df = pd.DataFrame(triples, columns=[\"head_id\", \"relation_id\", \"tail_id\"])\n",
        "\n",
        "df[\"head\"] = df[\"head_id\"].map(train_factory.entity_id_to_label)\n",
        "df[\"relation\"] = df[\"relation_id\"].map(train_factory.relation_id_to_label)\n",
        "df[\"tail\"] = df[\"tail_id\"].map(train_factory.entity_id_to_label)\n",
        "\n",
        "df = df[[\"head\", \"relation\", \"tail\"]]\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparing Triples for Embedding Models**"
      ],
      "metadata": {
        "id": "Daq9ezGNAIzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_AsgJiwhWz3",
        "outputId": "bfa87452-ed8b-461b-8fec-0483e16c9705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities: 129262\n",
            "Relations: 30\n",
            "Triples: torch.Size([6479992, 3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3547062096.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  triples_tensor = torch.tensor(train_factory.mapped_triples, dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "triples_tensor = torch.tensor(train_factory.mapped_triples, dtype=torch.long)\n",
        "num_entities = dataset.num_entities\n",
        "num_relations = dataset.num_relations\n",
        "\n",
        "print(\"Entities:\", num_entities)\n",
        "print(\"Relations:\", num_relations)\n",
        "print(\"Triples:\", triples_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining the DistMult model**"
      ],
      "metadata": {
        "id": "nr-1hWiVAgvb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "swuBn1FOhWz3"
      },
      "outputs": [],
      "source": [
        "model = DistMult(\n",
        "    num_nodes = num_entities,\n",
        "    num_relations = num_relations,\n",
        "    hidden_channels = 128,\n",
        "    margin = 1.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the DistMult model with Negative Sampling**"
      ],
      "metadata": {
        "id": "vw5Nc4hIBth2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, triples, num_entities, epochs=100, lr=0.01, weight_decay=1e-5):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        h = triples[:, 0]\n",
        "        r = triples[:, 1]\n",
        "        t = triples[:, 2]\n",
        "\n",
        "        pos_score = model(h, r, t)\n",
        "\n",
        "        mask = torch.rand(len(h)) < 0.5\n",
        "        h_neg = h.clone()\n",
        "        t_neg = t.clone()\n",
        "        h_neg[mask] = torch.randint(0, num_entities, (mask.sum().item(),), dtype=torch.long)\n",
        "        t_neg[~mask] = torch.randint(0, num_entities, ((~mask).sum().item(),), dtype=torch.long)\n",
        "\n",
        "        neg_score = model(h_neg, r, t_neg)\n",
        "\n",
        "        loss = F.softplus(neg_score + model.margin - pos_score).mean()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.node_emb.weight.div_(model.node_emb.weight.norm(dim=1, keepdim=True) + 1e-9)\n",
        "            model.rel_emb.weight.div_(model.rel_emb.weight.norm(dim=1, keepdim=True) + 1e-9)\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "triples_tensor = torch.tensor(train_factory.mapped_triples[:100000], dtype=torch.long)\n",
        "train(model, triples_tensor, num_entities=num_entities, epochs=100, lr=0.01)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah1_LyorAY2m",
        "outputId": "23dfaf8b-5a0b-4943-b6c1-2d5b2c1c4ac4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2518443917.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  triples_tensor = torch.tensor(train_factory.mapped_triples[:100000], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Loss: 1.3133\n",
            "Epoch 6/100 | Loss: 1.3195\n",
            "Epoch 11/100 | Loss: 1.3144\n",
            "Epoch 16/100 | Loss: 1.3072\n",
            "Epoch 21/100 | Loss: 1.3031\n",
            "Epoch 26/100 | Loss: 1.3009\n",
            "Epoch 31/100 | Loss: 1.2989\n",
            "Epoch 36/100 | Loss: 1.2979\n",
            "Epoch 41/100 | Loss: 1.2977\n",
            "Epoch 46/100 | Loss: 1.2980\n",
            "Epoch 51/100 | Loss: 1.2983\n",
            "Epoch 56/100 | Loss: 1.2984\n",
            "Epoch 61/100 | Loss: 1.2980\n",
            "Epoch 66/100 | Loss: 1.2972\n",
            "Epoch 71/100 | Loss: 1.2960\n",
            "Epoch 76/100 | Loss: 1.2949\n",
            "Epoch 81/100 | Loss: 1.2938\n",
            "Epoch 86/100 | Loss: 1.2930\n",
            "Epoch 91/100 | Loss: 1.2924\n",
            "Epoch 96/100 | Loss: 1.2918\n",
            "Epoch 100/100 | Loss: 1.2916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computing Probabilistic Priors from the trained model**"
      ],
      "metadata": {
        "id": "nnq1hx2LB29Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUeVR-uchWz4",
        "outputId": "2db1e066-7aa9-4bbb-9626-cddd3f16d3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'de novo' AMP biosynthetic process --bioprocess_bioprocess--> AMP biosynthetic process  [prior=0.518]\n",
            "'de novo' AMP biosynthetic process --bioprocess_protein--> ADSL  [prior=0.504]\n",
            "'de novo' CTP biosynthetic process --bioprocess_bioprocess--> CTP biosynthetic process  [prior=0.514]\n",
            "'de novo' GDP-L-fucose biosynthetic process --bioprocess_bioprocess--> GDP-L-fucose biosynthetic process  [prior=0.514]\n",
            "'de novo' IMP biosynthetic process --bioprocess_bioprocess--> IMP biosynthetic process  [prior=0.515]\n",
            "'de novo' L-methionine biosynthetic process --bioprocess_bioprocess--> L-methionine biosynthetic process  [prior=0.513]\n",
            "'de novo' NAD biosynthetic process --bioprocess_bioprocess--> 'de novo' NAD biosynthetic process from aspartate  [prior=0.508]\n",
            "'de novo' NAD biosynthetic process from aspartate --bioprocess_bioprocess--> 'de novo' NAD biosynthetic process  [prior=0.508]\n",
            "'de novo' NAD biosynthetic process from tryptophan --bioprocess_bioprocess--> 'de novo' NAD biosynthetic process  [prior=0.507]\n",
            "'de novo' UMP biosynthetic process --bioprocess_bioprocess--> UMP biosynthetic process  [prior=0.513]\n"
          ]
        }
      ],
      "source": [
        "def compute_priors(model, triples_tensor, factory, sample_size=200):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        n = min(sample_size, triples_tensor.size(0))\n",
        "        h = triples_tensor[:n, 0]\n",
        "        r = triples_tensor[:n, 1]\n",
        "        t = triples_tensor[:n, 2]\n",
        "\n",
        "        scores = model(h, r, t)\n",
        "        scores = torch.clamp(scores, min=-10.0, max=10.0)\n",
        "        probs = torch.sigmoid(scores)\n",
        "\n",
        "    result = []\n",
        "    for i in range(n):\n",
        "        result.append({\n",
        "            \"head\":    factory.entity_id_to_label[h[i].item()],\n",
        "            \"relation\":factory.relation_id_to_label[r[i].item()],\n",
        "            \"tail\":    factory.entity_id_to_label[t[i].item()],\n",
        "            \"prior\":   float(probs[i].item())\n",
        "        })\n",
        "    return result\n",
        "\n",
        "subset_priors = compute_priors(model, triples_tensor, train_factory, sample_size=200000)\n",
        "for row in subset_priors[:10]:\n",
        "    print(f\"{row['head']} --{row['relation']}--> {row['tail']}  [prior={row['prior']:.3f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert priors into a Tensor for inference**"
      ],
      "metadata": {
        "id": "l9PkTd3n7xUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "priors = torch.tensor([row[\"prior\"] for row in subset_priors], dtype=torch.float32)\n",
        "n_triples = len(priors)\n",
        "print(f\"Using {n_triples} triples for probabilistic inference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzCZ-F1N705A",
        "outputId": "add9a2d9-d5ea-4e7f-ba2b-00f5b5848fd8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 100000 triples for probabilistic inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bayesian Posterior Inference using Pyro (Per Triple)**"
      ],
      "metadata": {
        "id": "PgacJMDn_Lvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beta_bernoulli_model(prior_probs, concentration=10.0):\n",
        "    n = len(prior_probs)\n",
        "    alpha = prior_probs * concentration + 1.0\n",
        "    beta = (1.0 - prior_probs) * concentration + 1.0\n",
        "    with pyro.plate(\"triples\", n):\n",
        "        p = pyro.sample(\"p\", dist.Beta(alpha, beta))\n",
        "        pyro.sample(\"obs\", dist.Bernoulli(probs=p), obs=torch.ones(n))"
      ],
      "metadata": {
        "id": "6BNXwXhF_QkL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run MCMC with NUTS**"
      ],
      "metadata": {
        "id": "MaXfBSm6_Ubw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nuts_kernel = NUTS(beta_bernoulli_model)\n",
        "mcmc = MCMC(nuts_kernel, num_samples=500, warmup_steps=100)\n",
        "mcmc.run(priors)\n",
        "\n",
        "posterior_samples = mcmc.get_samples()[\"p\"]\n",
        "posterior_means = posterior_samples.mean(dim=0).detach().numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvgiEaFR_YQ1",
        "outputId": "99f905a4-1146-4bdb-ffa3-a3db37b0eb81"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sample: 100%|██████████| 600/600 [10:33,  1.06s/it, step size=9.96e-02, acc. prob=0.798]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Posterior estimates**"
      ],
      "metadata": {
        "id": "eBTBtVc-_dT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_posteriors = pd.DataFrame({\n",
        "    'head': [row['head'] for row in subset_priors],\n",
        "    'relation': [row['relation'] for row in subset_priors],\n",
        "    'tail': [row['tail'] for row in subset_priors],\n",
        "    'prior': [row['prior'] for row in subset_priors],\n",
        "    'posterior_mean': posterior_means\n",
        "})\n",
        "\n",
        "print(df_posteriors.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoUL6jQ7_mNl",
        "outputId": "79b4fad8-2923-454e-ec23-42c9e005dd02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          head               relation  \\\n",
            "0           'de novo' AMP biosynthetic process  bioprocess_bioprocess   \n",
            "1           'de novo' AMP biosynthetic process     bioprocess_protein   \n",
            "2           'de novo' CTP biosynthetic process  bioprocess_bioprocess   \n",
            "3  'de novo' GDP-L-fucose biosynthetic process  bioprocess_bioprocess   \n",
            "4           'de novo' IMP biosynthetic process  bioprocess_bioprocess   \n",
            "\n",
            "                                tail     prior  posterior_mean  \n",
            "0           AMP biosynthetic process  0.518474        0.551360  \n",
            "1                               ADSL  0.503805        0.535268  \n",
            "2           CTP biosynthetic process  0.514375        0.547528  \n",
            "3  GDP-L-fucose biosynthetic process  0.514290        0.551204  \n",
            "4           IMP biosynthetic process  0.514777        0.550747  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUYzj_x4iy3u"
      },
      "source": [
        "# **Connect to Neo4j**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0sSCjzYriy3u"
      },
      "outputs": [],
      "source": [
        "NEO4J_URI=\"neo4j+s://36039b8d.databases.neo4j.io\"\n",
        "NEO4J_USERNAME=\"neo4j\"\n",
        "NEO4J_PASSWORD=\"2GSEZotjB6q0ZB8CBDP36BPfhOo4Ip60hPLTURPIqrU\"\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Upload the triplets**"
      ],
      "metadata": {
        "id": "Qzuuvd4JCDNA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2lMAgTXKiy3u"
      },
      "outputs": [],
      "source": [
        "def upload_triples_with_confidence(driver, records, batch_size=1000, mode=\"prior\"):\n",
        "    assert mode in {\"prior\", \"posterior\", \"both\"}, \"mode must be 'prior', 'posterior', or 'both'\"\n",
        "\n",
        "    with driver.session() as session:\n",
        "        for i in range(0, len(records), batch_size):\n",
        "            batch = records[i: i + batch_size]\n",
        "            cypher = \"\"\"\n",
        "                UNWIND $batch AS rec\n",
        "                MERGE (h:Entity {name: rec.head})\n",
        "                MERGE (t:Entity {name: rec.tail})\n",
        "                MERGE (h)-[r:RELATION {type: rec.relation}]->(t)\n",
        "            \"\"\"\n",
        "            if mode == \"prior\":\n",
        "                cypher += \" SET r.prior = rec.prior\"\n",
        "            elif mode == \"posterior\":\n",
        "                cypher += \" SET r.posterior = rec.posterior\"\n",
        "            elif mode == \"both\":\n",
        "                cypher += \" SET r.prior = rec.prior, r.posterior = rec.posterior\"\n",
        "\n",
        "            session.run(cypher, batch=batch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build an in-memory graph**"
      ],
      "metadata": {
        "id": "wZcCkI9mTPKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_graph_with_posteriors(df):\n",
        "    graph = defaultdict(list)\n",
        "    for _, row in df.iterrows():\n",
        "        h = row[\"head\"]\n",
        "        t = row[\"tail\"]\n",
        "        r = row[\"relation\"]\n",
        "        p = row[\"posterior_mean\"]\n",
        "        graph[h].append((t, r, p))\n",
        "        graph[t].append((h, r, p))\n",
        "    return graph\n",
        "\n",
        "graph = build_graph_with_posteriors(df_posteriors)\n"
      ],
      "metadata": {
        "id": "gNf8gueGASst"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define path-finding with Probabilities**"
      ],
      "metadata": {
        "id": "Ik6mT4WzAUX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_paths(graph, start, end, max_hops=4):\n",
        "    queue = deque([(start, [start], [], 1.0)])\n",
        "    paths = []\n",
        "\n",
        "    while queue:\n",
        "        node, path, rels, prob = queue.popleft()\n",
        "\n",
        "        if len(path) - 1 > max_hops:\n",
        "            continue\n",
        "\n",
        "        for neighbor, relation, p in graph.get(node, []):\n",
        "            if neighbor in path:\n",
        "                continue\n",
        "            new_path = path + [neighbor]\n",
        "            new_rels = rels + [relation]\n",
        "            new_prob = prob * p\n",
        "            if neighbor == end:\n",
        "                paths.append((new_path, new_rels, new_prob))\n",
        "            else:\n",
        "                queue.append((neighbor, new_path, new_rels, new_prob))\n",
        "    return paths"
      ],
      "metadata": {
        "id": "S33m7LPNAp73"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aggregate Path Probabilities**"
      ],
      "metadata": {
        "id": "cPjTmLhAAxBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_path_probs(paths):\n",
        "    if not paths:\n",
        "        return 0.0\n",
        "    path_probs = [p for (_, _, p) in paths]\n",
        "    return 1.0 - np.prod([1.0 - p for p in path_probs])\n"
      ],
      "metadata": {
        "id": "cqHm3llwAzeA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multihop Inference Query function**"
      ],
      "metadata": {
        "id": "VGTRoVZcA1BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_multihop(graph, start, end, max_hops=5, verbose=True):\n",
        "    paths = find_paths(graph, start, end, max_hops)\n",
        "    p_final = aggregate_path_probs(paths)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"P({start} → {end}) ≈ {p_final:.3f} via {len(paths)} path(s)\")\n",
        "        for path, rels, prob in paths[:5]:\n",
        "            steps = \" → \".join(f\"{path[i]} -[{rels[i]}]\" for i in range(len(rels))) + f\" → {path[-1]}\"\n",
        "            print(f\"  Path ({len(rels)} hop{'s' if len(rels) > 1 else ''}): {steps}  (p ≈ {prob:.3f})\")\n",
        "\n",
        "    return p_final\n"
      ],
      "metadata": {
        "id": "t2vZmrhhA6PY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run multihop inference**"
      ],
      "metadata": {
        "id": "MinbWfqnA75l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_multihop(graph, \"'de novo' AMP biosynthetic process\", \"ADSL\", max_hops=10)\n",
        "print(\"\\n\")\n",
        "query_multihop(graph, \"'de novo' AMP biosynthetic process\", \"ADSS2\", max_hops=10)\n",
        "print(\"\\n\")\n",
        "query_multihop(graph, \"'de novo' AMP biosynthetic process\", \"AMP biosynthetic process\", max_hops=10)\n",
        "print(\"\\n\")\n",
        "query_multihop(graph, \"'de novo' AMP biosynthetic process\", \"AMP metabolic process\", max_hops=10)\n",
        "print(\"\\n\")\n",
        "query_multihop(graph, \"'de novo' AMP biosynthetic process\", \"AMP catabolic process\", max_hops=10)\n",
        "print(\"\\n\")\n",
        "query_multihop(graph, \"'de novo' AMP biosynthetic process\", \"ATP biosynthetic process\", max_hops=10)\n",
        "print(\"\\n\")\n",
        "query_multihop(graph, \"'de novo' AMP biosynthetic process\", \"ATP metabolic process\", max_hops=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIir0o2UA_AS",
        "outputId": "db50ab7b-9221-4239-a260-5cbf990eae32"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('de novo' AMP biosynthetic process → ADSL) ≈ 0.535 via 1 path(s)\n",
            "  Path (1 hop): 'de novo' AMP biosynthetic process -[bioprocess_protein] → ADSL  (p ≈ 0.535)\n",
            "\n",
            "\n",
            "P('de novo' AMP biosynthetic process → ADSS2) ≈ 0.542 via 1 path(s)\n",
            "  Path (1 hop): 'de novo' AMP biosynthetic process -[bioprocess_protein] → ADSS2  (p ≈ 0.542)\n",
            "\n",
            "\n",
            "P('de novo' AMP biosynthetic process → AMP biosynthetic process) ≈ 0.551 via 1 path(s)\n",
            "  Path (1 hop): 'de novo' AMP biosynthetic process -[bioprocess_bioprocess] → AMP biosynthetic process  (p ≈ 0.551)\n",
            "\n",
            "\n",
            "P('de novo' AMP biosynthetic process → AMP metabolic process) ≈ 0.295 via 1 path(s)\n",
            "  Path (2 hops): 'de novo' AMP biosynthetic process -[bioprocess_bioprocess] → AMP biosynthetic process -[bioprocess_bioprocess] → AMP metabolic process  (p ≈ 0.295)\n",
            "\n",
            "\n",
            "P('de novo' AMP biosynthetic process → AMP catabolic process) ≈ 0.160 via 1 path(s)\n",
            "  Path (3 hops): 'de novo' AMP biosynthetic process -[bioprocess_bioprocess] → AMP biosynthetic process -[bioprocess_bioprocess] → AMP metabolic process -[bioprocess_bioprocess] → AMP catabolic process  (p ≈ 0.160)\n",
            "\n",
            "\n",
            "P('de novo' AMP biosynthetic process → ATP biosynthetic process) ≈ 0.088 via 1 path(s)\n",
            "  Path (4 hops): 'de novo' AMP biosynthetic process -[bioprocess_bioprocess] → AMP biosynthetic process -[bioprocess_bioprocess] → AMP metabolic process -[bioprocess_bioprocess] → AMP phosphorylation -[bioprocess_bioprocess] → ATP biosynthetic process  (p ≈ 0.088)\n",
            "\n",
            "\n",
            "P('de novo' AMP biosynthetic process → ATP metabolic process) ≈ 0.048 via 1 path(s)\n",
            "  Path (5 hops): 'de novo' AMP biosynthetic process -[bioprocess_bioprocess] → AMP biosynthetic process -[bioprocess_bioprocess] → AMP metabolic process -[bioprocess_bioprocess] → AMP phosphorylation -[bioprocess_bioprocess] → ATP biosynthetic process -[bioprocess_bioprocess] → ATP metabolic process  (p ≈ 0.048)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.047802575437012496)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}